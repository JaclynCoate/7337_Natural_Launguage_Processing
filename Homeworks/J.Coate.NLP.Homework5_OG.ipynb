{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS 7337: Natural Language Processing\n",
    "\n",
    "## Jaclyn Coate\n",
    "## Homework 5\n",
    "\n",
    "#### Spring 2021\n",
    "#### Natural Language Processing w/ Python: Bird, Klein, & Loper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs4 4.8.2\n",
      "nltk 3.4.5\n",
      "re 2.2.1\n",
      "requests 2.22.0\n"
     ]
    }
   ],
   "source": [
    "# Environment Prep\n",
    "import bs4; print( 'bs4 ' + bs4.__version__)\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "import nltk; print( 'nltk ' + nltk.__version__)\n",
    "from nltk import word_tokenize, pos_tag, RegexpParser;\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import re; print('re ' + re.__version__)\n",
    "import requests; print('requests ' + requests.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HW 5: Question 1\n",
    "Compile a list of static links (permalinks) to individual user movie reviews from one particular website. This will be your working dataset for this assignment, as well as for assignments 7 and 8, which together will make up your semester project.   \n",
    "\n",
    "a. It does not matter if you use a crawler or if you manually collect the links, but you will need at least 100 movie review links. Note that, as of this writing, the robots.txt file of IMDB.com allows the crawling of user reviews.  \n",
    "\n",
    "b. Each link should be to a web page that has only one user review of only one movie, e.g., the user review permalinks on the IMDB site.  \n",
    "\n",
    "c.\tChoose reviews of movies that are all in the same genre, e.g., sci-fi, mystery, romance, superhero, etc.  \n",
    "\n",
    "d.\tMake sure your collection includes reviews of several movies in your chosen genre and that it includes a mix of negative and positive reviews.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source links for Top Horror Movies in History and store in review_home_url\n",
    "review_home_url = {\n",
    "    'The Exorcist': 'https://www.imdb.com/title/tt0070047/reviews?ref_=tt_ql_3',\n",
    "    'Paranormal Activity': 'https://www.imdb.com/title/tt1179904/reviews?ref_=tt_ql_3',\n",
    "    'Hellraiser': 'https://www.imdb.com/title/tt0093177/reviews?ref_=tt_ql_3',\n",
    "    'A Nightmare on Elm Street': 'https://www.imdb.com/title/tt0087800/reviews?ref_=tt_ql_3',\n",
    "    'American Psycho' : 'https://www.imdb.com/title/tt0087800/reviews?ref_=tt_ql_3',\n",
    "    'The Blair Witch Project': 'https://www.imdb.com/title/tt0185937/reviews?ref_=tt_ql_3',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to grab text from the URL: grab_text_from_url\n",
    "def get_text_from_url(url):\n",
    "    return requests.get(url).text\n",
    "text = get_text_from_url(review_home_url['The Exorcist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function points to the links within the HTML\n",
    "def get_all_html_links(html):\n",
    "    tags = BeautifulSoup(html, 'html.parser', parse_only=SoupStrainer('a', href=True))\n",
    "    urls = [str(tag.attrs['href']) for tag in tags]\n",
    "    return urls\n",
    "all_links = get_all_html_links(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_review_links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e0ffac7e7d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0murl_template\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_review_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_review_links' is not defined"
     ]
    }
   ],
   "source": [
    "# This defintion sets the URL template and allows the unique urls to be grabbed after the root url\n",
    "def get_review_links(links):\n",
    "    url_template = 'https://www.imdb.com{}'\n",
    "   \n",
    "    return [url_template.format(link) for link in links]\n",
    "\n",
    "urls = get_review_links(all_links);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This defines the relevent part of the link by calling our review section to point to HTML post the root 'review'\n",
    "def relevent_link(link):\n",
    "    if '/review/' in link:\n",
    "        return True\n",
    "    return False\n",
    "def get_relevent_links(links):\n",
    "    relevent_links = filter(relevent_link, all_links)\n",
    "    unique_relevent_links = set(relevent_links)\n",
    "    return list(unique_relevent_links)\n",
    "relevent_urls = get_relevent_links(urls)\n",
    "len(relevent_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HW 5: Question 2\n",
    "Extract noun phrase (NP) chunks from your reviews using the following procedure:  \n",
    "\n",
    "a. In Python, use BeautifulSoup to grab the main review text from each link.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing reviews rfom sites\n",
    "def strain_content(name, attrs):\n",
    "    if name == 'div' and dict(attrs).get('class', None) == 'content':\n",
    "        return True\n",
    "    return False\n",
    "def clean_review_text(text):\n",
    "    return re.split('\\\\n\\\\n\\s+\\d+ out of \\d+', text)[0]\n",
    "def get_review_from_url(url):\n",
    "    html = get_text_from_url(url)\n",
    "    tags = BeautifulSoup(html, 'html.parser', parse_only=SoupStrainer(strain_content))\n",
    "    review = clean_review_text(tags.text)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing reviews rfom sites\n",
    "def get_review_from_site(url):\n",
    "    reviews = []\n",
    "\n",
    "    reviews_home_text = get_text_from_url(url)\n",
    "    all_links = get_all_html_links(reviews_home_text)\n",
    "    relevent_links = get_relevent_links(all_links)\n",
    "\n",
    "    review_urls = get_review_urls_from_links(relevent_links)\n",
    "    for url in review_urls:\n",
    "        reviews.append(get_review_from_url(url))\n",
    "        # break\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating the review sectiosn from the sites \n",
    "def get_reviews_from_all_sites():\n",
    "    all_reviews = []\n",
    "    review_titles = review_home_urls.keys()\n",
    "    for title in review_titles:\n",
    "        review_home_url = review_home_urls[title]\n",
    "        all_reviews = all_reviews + get_review_from_site(review_home_url)\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The defintions for Part of Speech tagging\n",
    "def pos_tagging_for_review(sentence):\n",
    "    cleaned_review = sentence.lower()\n",
    "    tokenized_review = word_tokenize(cleaned_review)\n",
    "    return pos_tag(tokenized_review)\n",
    "def get_chunking_for_sentence(sentence):\n",
    "    tagged_sentence = pos_tagging_for_review(sentence)\n",
    "\n",
    "    grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    result = cp.parse(tagged_sentence)\n",
    "    return result\n",
    "\n",
    "def get_chunking_for_review(review):\n",
    "    sentences = sent_tokenize(review)\n",
    "    result = [get_chunking_for_sentence(sentence) for sentence in sentences]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Next run each review text through a tokenizer, and then try to NP-chunk it with a shallow parser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the funtion for chunking the reviews\n",
    "def get_chunking_for_reviews(reviews):\n",
    "    return [get_chunking_for_review(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for identifying noun phrases for chunking\n",
    "def get_NP_for_review(review):\n",
    "    main_trees = get_chunking_for_review(review)\n",
    "    subtrees = []\n",
    "    for main_tree in main_trees:\n",
    "        for subtree in main_tree.subtrees():\n",
    "            if subtree.label() == 'NP':\n",
    "                subtrees.append(subtree)\n",
    "    return subtrees[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning those noun phrases\n",
    "def get_NP_for_reviews(reviews):\n",
    "    return [get_NP_for_review(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'review_home_urls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-18a07c55cce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Grabbign reviews and placing them in one place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reviews_from_all_sites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-9bbee48abff7>\u001b[0m in \u001b[0;36mget_reviews_from_all_sites\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_reviews_from_all_sites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mall_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mreview_titles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_home_urls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview_titles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mreview_home_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_home_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'review_home_urls' is not defined"
     ]
    }
   ],
   "source": [
    "# Grabbign reviews and placing them in one place\n",
    "all_reviews = get_reviews_from_all_sites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ab12a6d61897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Quick view of all reivews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "# Quick view of all reivews\n",
    "print(len(all_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. You probably will have too many unknown words, owing to proper names of characters, actors, and so on that are not in your working dictionary. Make sure the main names that are relevant to the movies in your collection of reviews are added to the working lexicon, and then run the NP chunker again.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-95284d3fca08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoun_phrases_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_NP_for_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "noun_phrases_reviews = get_NP_for_reviews(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noun_phrases_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d3efc775f5dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Grabbing noun phrases w/ 4 word range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mnoun_phrases\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoun_phrases_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoun_phrases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'noun_phrases_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "# Grabbing noun phrases w/ 4 word range\n",
    "for noun_phrases in noun_phrases_reviews[0:4]:\n",
    "    for i in range(4):\n",
    "        print(noun_phrases[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HW 5: Question 3\n",
    "\n",
    "Output all the chunks in a single list for each review, and submit that output for this assignment. Also submit a brief written summary of what you did (describe your selection of genre, your source of reviews, how many you collected, and by what means).\n",
    "\n",
    "In order to collect movies and their reviewes I sourced reviews from the reviews pages of the top 6 horror movies of all time. I sourced the reviews from IMDB.com, one of the most proliferent movie review pages of all time. I collected and sourced the movies parsing HTML out of URL with the tool beautifulsoup in Python. I used NLTK to word chunk and identify *noun phrases* for review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noun_phrases_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-563a013dcc22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoun_phrases_reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'noun_phrases_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "noun_phrases_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
